{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "-----\n",
    "## Table of Contents\n",
    "\n",
    "\n",
    "## Introduction\n",
    "Decide what you’re modeling, and what will determine its success (what is your X, Y, and evaluation strategy?)\n",
    "Getting data (inputs are from database management) and making it model-ready: dealing with nulls and missing values, feature generation, separate into training and test set. Each row should be an individual coupled with a timestamp. They should bring in all available data about this person at this time. \n",
    "Train models and choose the best based on your evaluation strategy\n",
    "Error analysis: Categorizing errors, seeing if there are any identifiable patterns to the errors that you’re making and if you are OK with making those errors.  \n",
    "Prediction and interpretation: apply the model to new data and say what we can conclude from it and what policy recommendations this suggests.\n",
    "Now take the same individual level information and change outcome variable: recidivism, whether they have a job, etc. What else do you find? How does this change feature generation and evaluation?\n",
    "Need to decide what we want them to actually do in this exercise to figure out the overall work.\n",
    "If just play with scikit-learn, then probably will provide an already-flattened table that they can then load and use to try out different models. \n",
    "Another option is to have them build the data from a person’s records, but this would be a lot more work.\n",
    "Research questions:\n",
    "All cohorts - predict stable employment - full-quarter employment status?\n",
    "Ex-offenders - Predict recidivism\n",
    "\n",
    "This tutorial is based on chapter 6 of [Big Data and Social Science](https://github.com/BigDataSocialScience/).\n",
    "\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand the basic concepts of supervised and unsupervised machine learning, how this differs from modeling for interpretation (which they are most likely more familiar with), and how it can be used for policy applications.\n",
    "- Use ML packages in Python to bring in individual-level data combined across multiple sources; determine and generate appropriate features, outcome variables, evaluation methods and training/test splits; identify a best model and conduct error analysis and provide interpretation within context.\n",
    "\n",
    "## Table of Contents\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glossary of Terms \n",
    "- **Learning**: In machine learning, you'll hear about \"learning a model.\" This is what you probably know as \n",
    "*fitting* or *estimating* a function, or *training* or *building* a model. These terms are all synonyms and are \n",
    "used interchangeably in the machine learning literature.\n",
    "- **Examples**: These are what you probably know as *data points* or *observations*. \n",
    "- **Features**: These are what you probably know as *independent variables*, *attributes*, *predictors*, \n",
    "or *explanatory variables.*\n",
    "- **Underfitting**: This happens when a model is too simple and does not capture the structure of the data well \n",
    "enough.\n",
    "- **Overfitting**: This happens when a model is too complex or too sensitive to the noise in the data; this can\n",
    "result in poor generalization performance, or applicability of the model to new data. \n",
    "- **Regularization**: This is a general method to avoid overfitting by applying additional constraints to the model. \n",
    "For example, you can limit the number of features present in the final model, or the weight coefficients applied\n",
    "to the (standardized) features are small.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Before we begin, run the code cell below to initialize the libraries we'll be using in this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named sql_alchemy",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b6677366cf0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msql_alchemy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named sql_alchemy"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from sql_alchemy import create_engine\n",
    "import pandas\n",
    "import statsmodels\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Basics\n",
    "We'll be using criminal justice data. \n",
    "Data documentation\n",
    "How to connect to the database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up database credentials\n",
    "mysql_username = \"<username>\"\n",
    "mysql_password = \"<password>\"\n",
    "mysql_host = \"cuspdev.local\"\n",
    "mysql_port = \"3306\"\n",
    "mysql_database = \"homework\"\n",
    "mysql_charset = \"utf8\"\n",
    "\n",
    "# Create database connection for pandas.\n",
    "pandas_db = create_engine( \"mysql+pymysql://\" + mysql_username + \":\" + mysql_password + \"@\" + \n",
    "                          mysql_host + \":\" + mysql_port + \"/\" + mysql_database + \"?charset=\" + mysql_charset )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Machine Learning Process\n",
    "\n",
    "- **Understand the problem and goal.** *This sounds obvious but is often nontrivial.* Problems typically start as vague \n",
    "descriptions of a goal - improving health outcomes, increasing graduation rates, understanding the effect of a \n",
    "variable *X* on an outcome *Y*, etc. It is really important to work with people who understand the domain being\n",
    "studied to dig deeper and define the problem more concretely. What is the analytical formulation of the metric \n",
    "that you are trying to optimize?\n",
    "- **Formulate it as a machine learning problem.** Is it a classification problem or a regression problem? Is the \n",
    "goal to build a model that generates a ranked list prioritized by risk, or is it to detect anomalies as new data \n",
    "come in? Knowing what kinds of tasks machine learning can solve will allow you to map the problem you are working on\n",
    "to one or more machine learning settings and give you access to a suite of methods.\n",
    "- **Data exploration and preparation.** Next, you need to carefully explore the data you have. What additional data\n",
    "do you need or have access to? What variable will you use to match records for integrating different data sources?\n",
    "What variables exist in the data set? Are they continuous or categorical? What about missing values? Can you use the \n",
    "variables in their original form, or do you need to alter them in some way?\n",
    "- **Feature engineering.** In machine learning language, what you might know as independent variables or predictors \n",
    "or factors or covariates are called \"features.\" Creating good features is probably the most important step in the \n",
    "machine learning process. This involves doing transformations, creating interaction terms, or aggregating over data\n",
    "points or over time and space.\n",
    "- **Method selection.** Having formulated the problem and created your features, you now have a suite of methods to\n",
    "choose from. It would be great if there were a single method that always worked best for a specific type of problem, \n",
    "but that would make things too easy. Typically, in machine learning, you take a collection \n",
    "- **Evaluation.** As you build a large number of possible models, you need a way to select the model that is the \n",
    "best. This part of the chapter will cover the validation methodology to first validate models on historical data\n",
    "as well as discuss a variety of evaluation metrics. The next step is to validate using a field trial or experiment.\n",
    "- **Deployment.** Once you have selected the best model and validated it using historical data as well as a field\n",
    "trial, you are ready to put the model into practice. You still have to keep in mind that new data will be coming in,\n",
    "and the model might change over time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Formulation\n",
    "- **Supervised learning.** These are problems with one target or outcome variable (continuous or discrete) that we want\n",
    "to predict, or classify data into. Clasification, prediction, and regression fall into this category. We call the\n",
    "set of explanatory variables $X$ **features**, and the outcome variable of interest the **label**.\n",
    "- **Unsupervised learning** involves problems that do not have a specific outcome variable of interest, but rather\n",
    "we are looking to understand \"natural\" patterns or groupings in the data - looking to uncover some structure that \n",
    "we do not know about a priori. Clustering is the most common example of unsupervised learning. Another example is \n",
    "principal components analysis (PCA).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we'll be using the [pandas package](http://pandas.pydata.org/) to read in and manipulate data. Pandas provides an alternative to reading data directly from MySQL that stores the data in special table format called a \"data frame\" that allows for easy statistical analysis and can be directly used for machine learning. \n",
    "Pandas uses a database engine to connect to databases (via the SQLAlchemy Python package). In the code cell below, we will create a database engine conneted to our class MySQL database server for Pandas to use. In the code cell below, place your database username and password in the variables 'mysql_username' and 'mysql_password', then run the cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use this database connection to have pandas read in the data stored in the 'MachineLearning2' table. Pandas has a set of [Input/Output tools](http://pandas.pydata.org/pandas-docs/stable/io.html) that let it read from and write to a large variety of tabular data formats, including CSV and Excel files, databases via SQL, JSON files, and SAS and Stata data files. In the example below, we'll use the pandas.read_sql() function to read the results of an SQL query into a pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_frame = pandas.read_sql( 'SELECT * FROM homework.MachineLearning2;' pandas_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at what the data looks like. The pandas.DataFrame method 'data_frame.head( number_of_rows )' outputs the first number_of_rows rows in a data frame. Let's look at the first five rows in our data.\n",
    "In the code cell below, there are two ways to output this information. If you just call the method, you'll get an HTML table output directly into the ipython notebook. If you pass the results of the method to the \"print()\" function, you'll get text output that works outside of jupyter/ipython."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to get a pretty tabular view, just call the method.\n",
    "data_frame.head( 5 )\n",
    "\n",
    "# to get a text-based view, print() the call to the method.\n",
    "#print( data_frame.head( 5 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Data \n",
    "In pandas, our data is represented by a DataFrame. You can think of data frames as a giant spreadsheet which you can program, with the data for each column stored in its own list that pandas calls a Series (or vector of values), along with a set of methods (another name for functions that are tied to objects) that make managing data in pandas easy.\n",
    "\n",
    "A Series is a list of values each of which can also have a label, which pandas calls an \"index\", and which generally is used to store names of columns when you retrieve a Series that represents a row, and IDs of rows when you retrieve a Series that represents a column of data in a table.\n",
    "\n",
    "While DataFrames and Series are separate objects, they may share the same methods where those methods make sense in both a table and list context (head() and tail(), as used in examples in this notebook, for example).\n",
    "More details on pandas data structures:\n",
    "- [Data Structures Overview](http://pandas.pydata.org/pandas-docs/stable/dsintro.html)\n",
    "- [Series specifics](http://pandas.pydata.org/pandas-docs/stable/dsintro.html#series)\n",
    "- [DataFrame specifics](http://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get vector of \"ORG_DEPT\" column values from data frame\n",
    "org_dept_column_series = data_frame[ \"ORG_DEPT\" ]\n",
    "\n",
    "# see the last 5 values in the vector.\n",
    "print( org_dept_column_series.tail( 5 ) )\n",
    "\n",
    "# It is also OK to chain together, but I did not above for clarity's sake, and in\n",
    "#    general, be wary of doing too many things on one line.\n",
    "# data_frame[ \"ORG_DEPT\" ].tail( 5 )\n",
    "\n",
    "# empty org_dept_column_series variable and garbage collect, to conserve memory\n",
    "org_dept_column_series = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_frame.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas provides some [great functions for descriptive statistics](http://pandas.pydata.org/pandas-docs/stable/basics.html#descriptive-statistics). Some examples:\n",
    "\n",
    "- **`describe()`** - \"computes a variety of summary statistics about a Series or the columns of a DataFrame (excluding NAs of course)\" ( See [documentation](http://pandas.pydata.org/pandas-docs/stable/basics.html#summarizing-data-describe))\n",
    "\n",
    "    - includes the count of values, mean, standard deviation, min, 25%, 50%, and 75% values, and the max.\n",
    "\n",
    "- **`head()` and `tail()`**, shown above - \"To view a small sample of a Series or DataFrame object, use the `head()` and `tail()` methods. The default number of elements to display is five, but you may pass a custom number.\" ( See [documentation](http://pandas.pydata.org/pandas-docs/stable/basics.html#head-and-tail).\n",
    "- **`value_counts()`** - The `value_counts()` \"series method and top-level function computes a histogram of a one-dimensional array of values.\" ( See [documentation](http://pandas.pydata.org/pandas-docs/stable/basics.html#value-counts-histogramming-mode) ).  This method returns a Series of the counts of the number of times each unique value in the column is present in the column (also known as frequencies), from largest count to least, with the value itself the label for each row.\n",
    "\n",
    "For the first part of exercise 1, we will combine some of these methods for calculating descriptive statistics into a function that accepts a DataFrame of data from our `homework.MachineLearning2` table, then calculates and returns both the descriptives for the columns in the table and the top ten most frequently referenced departments.\n",
    "\n",
    "We will be making a function that returns multiple values to help you understand how this works in Python, since some of the machine learning functions used below return multiple values.\n",
    "\n",
    "In a Python function, if you want to return multiple values, you place each in the line with your return statement, separated by commas.  This is like a list of variables, but you don't need to put it in square brackets.  You just place the items after the `return` keyword.  So, if you wanted to write a function that returns the circumference and area of a circle when passed the radius of a circle (run the cell below):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "Now that we have a clean dataset, we can move on to the fun parts!! The python machine learning libraries do not accept categorical variables, so we need to convert all such variables to dummies first (boolean variables that capture the presence or absence in a given row of each of the potential values for each categorical variable). However, pandas makes it super easy! \n",
    "\n",
    "But before we do that, lets split our data variables into predictors (features, or dependent variables, or \"X\" variables) and variables to predict (independent variables, or \"Y\" variables).  For ease of reference, in subsequent examples, names of variables that pertain to predictors will start with \"`X_`\", and names of variables that pertain to variables we are to predict will start with \"`y_`\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets go ahead and split into predictors and predicted\n",
    "\n",
    "# make a list of the column names not in dependent column name list (currently just \"ORG_DEPT\")\n",
    "# one line - predictor_column_list = [ column_name for column_name in list( cleaned_data_frame.columns.values ) if column_name not in [ \"ORG_DEPT\" ] ]\n",
    "X_column_list = []\n",
    "y_column_list = [ \"ORG_DEPT\" ]\n",
    "\n",
    "# loop over column names.\n",
    "column_name_list = cleaned_data_frame.columns.values\n",
    "for column_name in column_name_list:\n",
    "    \n",
    "    # if the name is not predicted_column_list, add it to predictor_column_list\n",
    "    if ( column_name not in y_column_list ):\n",
    "        \n",
    "        # add to the predictor_column_list\n",
    "        X_column_list.append( column_name )\n",
    "        \n",
    "    #-- END check to see if column is in predicted/IV/Y list --#\n",
    "    \n",
    "#-- END loop over columns. --#\n",
    "\n",
    "# split columns into two DataFrames, those we are to predict,\n",
    "#    and those that are predictors.\n",
    "X_data_frame = cleaned_data_frame[ X_column_list ]\n",
    "y_data_frame = cleaned_data_frame[ y_column_list ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can easily convert all categorical variables in `X_data_frame` into dummy/binary variables using the `pandas.get_dummies()` function ( See [documentation](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python's sckikit algorithms dont work on categorical variables. Fortunately, Pandas provides an easy way out!\n",
    "X_data_frame = pandas.get_dummies( X_data_frame )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "Good features make machine learning systems effective. You generate features by a combination of domain knowledge and \n",
    "what has the most correlation. In general, it is better to have more complex features and a simpler model rather than vice versa. Keeping the model simple makes it faster to train and easier to understand. \n",
    "\n",
    "- **Transformations**, such a log, square, and square root.\n",
    "- **Dummy (binary) variables**, also known as *indicator variables*, often done by taking categorical variables\n",
    "(such as city) which do not have a numerical value, and adding them to models as a binary value.\n",
    "- **Discretization**. Several methods require features to be discrete instead of continuous. This is often done \n",
    "by binning, which you can do by equal width. \n",
    "- **Aggregation.** Aggregate features often constitute the majority of features for a given problem. These use \n",
    "different aggregation functions (*count, min, max, average, standard deviation, etc.*) which summarize several\n",
    "values into one figure, aggregating over varying windows of time and space. For example, given urban data, \n",
    "we would want to calculate the *number* (and *min, max, mean, variance*, etc.) of crimes within an *m*-mile radius\n",
    "of an address in the past *t* months for varying values of *m* and *t*, and then use all of them as features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "If we're building a model, we're going to need a way to know whether or not it's working. Convincing others of the quality of results is often the most challenging part of an analysis.  In machine learning, making repeatable, well-documented work with clear success metrics makes all the difference.\n",
    "\n",
    "For our classifier, we're going to use the following build methodology (Ghani, 2014):\n",
    "\n",
    "<img src=\"https://s3.amazonaws.com/demo-datasets/traintest.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In brief, this methodology involves:\n",
    "\n",
    "- First [**splitting your data**](#1.-Split-data-into-training-and-testing-data-sets) into a training set (75% of your data) and a test set (25% of your data).\n",
    "- \"**Feature engineering** is the process of transforming raw data into features that better represent the underlying problem/data to the predictive models, resulting in improved model accuracy on unseen data.\" ( from [Discover Feature Engineering](http://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/) ).  In text, for example, this might involve deriving traits of the text like word counts, verb counts, or topics to feed into a model rather than simply giving it the raw text.\n",
    "- In the [**Model Build**](#2.-Model-Build---Fit-model) phase, you decide on a model then train or fit your model using your training data.\n",
    "- In the [**Evaluate Performance**](#3.-Evaluate-Performance---accuracy) phase, you run your fitted model on your set of testing predictors, then assess the quality of the model by comparing the predicted values to the actual values for each record in your testing data set. \n",
    "\n",
    "Since we have a limited number of relatively basic features, we won't be going into any Feature Engineering examples for this exercise.  However, feature engineering is an essential part of implementing quality machine learning - to learn more, start with the \"Discover Feature Engineering\" tutorial: [http://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/](http://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/)\n",
    "\n",
    "Let us now split our dataset into test and training using the `train_test_split()` function from scikit learn's sklearn.cross_validation module ( [http://scikit-learn.org/stable/modules/cross_validation.html](http://scikit-learn.org/stable/modules/cross_validation.html) ):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split data into training and testing data sets\n",
    "\n",
    "Let us now split our dataset into test and training using the `train_test_split()` function from scikit learn's sklearn.cross_validation module ( [http://scikit-learn.org/stable/modules/cross_validation.html](http://scikit-learn.org/stable/modules/cross_validation.html) ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use train_test_split() to split our X and Y variables into separate 75% and 25%\n",
    "#    DataFrames of training (X_train and y_train) and testing (X_test and y_test) data.\n",
    "X_train, X_test, y_train, y_test = train_test_split( X_data_frame, y_data_frame, test_size = 0.25, random_state = 0 )\n",
    "\n",
    "# Before we fit the model, we also need to change the datatype of the y_train variable.\n",
    "# y_train currently is a Pandas Series, however, scikit-learn requires it to be a numpy array\n",
    "# So all we need to do is extract the raw values of y_train, and pass them onto scikit-learn\n",
    "y_train_values = y_train[ 'ORG_DEPT' ].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Build - Fit model\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Python's `scikit-learn` is a very well known machine library. It is also well documented and maintained. You can learn all about it here: [http://scikit-learn.org/stable/](http://scikit-learn.org/stable/). We will be using different classifiers from this library for our predictions in this workbook. \n",
    "\n",
    "We will start with the simplest `LogisticRegression` model ( [http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) ) and see how well that does.\n",
    "\n",
    "You can use any number of metrics to judge your models, but we will be using scikit learn's provided `accuracy_score()` (ratio of correct predictions to total number of predictions, based on comparing a set of predicted to values to a set of actual values) as our measure ( [http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's fit the model\n",
    "model = LogisticRegression()\n",
    "model.fit( X_train, y_train_values )\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we print the model, we see different parameters we can adjust as we refine the model based on running it against test data (values such as `intercept_scaling`, `max_iters`, `penalty`, and `solver`).  Example output:\n",
    "\n",
    "    LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
    "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
    "          verbose=0)\n",
    "\n",
    "To adjust these parameters, one would alter the call that creates the `LogisticRegression()` model instance, passing it one or more of these parameters with a value other than the default.  So, to re-fit the model with `max_iter` of 1000, `intercept_scaling` of 2, and `solver` of \"lbfgs\" (pulled from thin air as an example), you'd create your model as follows:\n",
    "\n",
    "    model = LogisticRegression( max_iter = 1000, intercept_scaling = 2, solver = \"lbfgs\" )\n",
    "\n",
    "More details on what each of thee parameters mean is on the `LogisticRegression` documentation page: [http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "\n",
    "The basic way one would tune these parameters is to iterate over fitting your model to your training data with different parameters (hopefully chosen based on your knowledge of your data and the model you are fitting), then testing it against training data until the model's accuracy is as high as you can get it.  Unfortunately, this exposes one to the potential that the model is over-fitted to one's test data, and so won't perform as well when it is used to predict other sets of data.\n",
    "\n",
    "Cross-validation is a good way to fine-tune the parameters with less risk of over-fitting.  It involves dividing your training data into 5 or so equal sets called folds, then choosing a different fold to serve as the test data set each time you test a new set of parameters. This sounds complicated, but scikit learn has functions to help, and a good tutorial on cross-validation can be found on the scikit learn site: [http://scikit-learn.org/stable/modules/cross_validation.html](http://scikit-learn.org/stable/modules/cross_validation.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate Performance - accuracy\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Now let's use the model we just fit to make predictions on our test dataset, and see what our accuracy score is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store our test \"to predict\" variables in \"expected\".\n",
    "expected = y_test\n",
    "\n",
    "# predict values from our \"predictors\" usin the model.\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "# generate an accuracy score by comparing expected to predicted.\n",
    "accuracy = accuracy_score(expected, predicted)\n",
    "print( \"Accuracy = \" + str( accuracy ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an accuracy score of 0.45340... (45%). This is not a great score, however, it is much better than random guessing, which would have had a chance of 1/18 of succeeding. The other way to guess would be to take the mode, which in this case is MEDICINE with a frequency of 22497, which would give us an accuracy score of 22497/49013 = 45.9%. So logistic regression is about as good as just always assigning the mode when department is missing. Let's see if other classifiers can do any better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "- ** Model Selection**: How do we select a method to use? What parameters should we select for that method?\n",
    "- **Performance Estimation**: How well will our model do once it is deployed and applied to new data?\n",
    "- **Deeper Understanding**: Are there inaccuracies in the predictions the model makes? Does the model uncover\n",
    "inconsistencies in the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3 - Train, fit and evaluate your model\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Complete the function below to train different classifiers from the scikit library.\n",
    "\n",
    "The `classifier()` function that you will implement:\n",
    "\n",
    "- Accepts X_train_IN, y_train_IN (should be type numpy.ndarray, not a Series or DataFrame - to convert, call \"`.values`\"), X_test_IN, and y_test_IN variables.\n",
    "- creates a model, fits the model, tests the model, and calculates an accuracy score for the model (like we did above).\n",
    "- returns the accuracy score as a percent (so a number between 1 and 100, not a decimal between 0 and 1 - ... so multiply by 100).\n",
    "\n",
    "Your goal is to come up with a classifier that gives at least 70% accuracy on the test dataset.  To do this, you can:\n",
    "\n",
    "- choose different models from those offered as part of scikit learn.\n",
    "\n",
    "    - To start, here are some resources to help with choosing a model:\n",
    "\n",
    "        - The scikit learn tutorial on choosing a model - [http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html](http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)\n",
    "        - This video on choosing and tuning a model - [http://blog.kaggle.com/2015/05/14/scikit-learn-video-5-choosing-a-machine-learning-model/](http://blog.kaggle.com/2015/05/14/scikit-learn-video-5-choosing-a-machine-learning-model/)\n",
    "    \n",
    "    - In particular, here are some sets of models you could explore from the \"predicting a category\" with \"labeled data\" branch of the [scikit learn tutorial on choosing a model](http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) (just make sure your data doesn't violate the assumptions of the model and that the model you choose is appropriate for your data - predicting a categorical variable using a mix of numeric and dummied categorical data):\n",
    "\n",
    "        - other Linear Models like the `LogisticRegression` - [http://scikit-learn.org/stable/modules/linear_model.htmlFeel](http://scikit-learn.org/stable/modules/linear_model.html)\n",
    "        - Decision Tree models - [http://scikit-learn.org/stable/modules/tree.html](http://scikit-learn.org/stable/modules/tree.html)\n",
    "        - Ensemble classifiers - [http://scikit-learn.org/stable/modules/ensemble.html](http://scikit-learn.org/stable/modules/ensemble.html)\n",
    "        - Nearest neighbors classifiers - [http://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-classification](http://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-classification)\n",
    "        - Stocahstic Gradient Descent - [http://scikit-learn.org/stable/modules/sgd.html#classification](http://scikit-learn.org/stable/modules/sgd.html#classification)\n",
    "        - Kernel Approximation + SGDClassifier - [http://scikit-learn.org/stable/modules/kernel_approximation.html](http://scikit-learn.org/stable/modules/kernel_approximation.html)\n",
    "\n",
    "- play around with different parameters for the models you try.\n",
    "- experiment with different sets of X variables.\n",
    "- _Advanced_ - You can try starting again from the top with an SQL query that uses JOINs to pull in columns from other tables, to add more variables to your pool of available predictors.\n",
    "- _Advanced_ - You could also try to derive additional features from the data present in your query and add those features to your predictors.\n",
    "\n",
    "Again, in general, make sure that the model and parameters you choose are appropriate for both your X and Y variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classifier(X_train_IN, y_train_IN, X_test_IN, y_test_IN):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train_IN : A pandas DataFrame of features used for training the classifier\n",
    "    y_train_IN : A numpy array of y values used for training the classifier\n",
    "    X_test_IN, y_test_IN : Use these to test the accuracy of your classifier\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    accuracy score : a float giving the percent (0 to 100) of accurate predictions you made\n",
    "    \"\"\"\n",
    "    \n",
    "    ### BEGIN SOLUTION\n",
    "    # declare variables\n",
    "    y_train_type = None\n",
    "    y_train_array = None\n",
    "    my_accuracy_score = -1\n",
    "   \n",
    "    # check to see if y_train_IN is either a Series or a DataFrame\n",
    "    y_train_type = type( y_train_IN )\n",
    "    if ( ( y_train_type == pandas.core.series.Series ) or ( y_train_type == pandas.core.frame.DataFrame ) ):\n",
    "        \n",
    "        # Series or DataFrame - convert to pandas array\n",
    "        y_train_array = y_train_IN.values\n",
    "        \n",
    "    elif ( y_train_type == numpy.ndarray ):\n",
    "        \n",
    "        # this is what it should be.\n",
    "        y_train_array = y_train_IN\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # not Series or DataFrame numpy ndarray - just use it and see what happens...?\n",
    "        print( \"Unexpected y_train_IN type: \" + str( y_train_type ) )\n",
    "        y_train_array = y_train_IN\n",
    "        \n",
    "    #-- END check to see if y_train_IN is wrong type. --#\n",
    "    \n",
    "    # for fitting model, use y_train_array rather than y_train_IN.\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train_IN, y_train_array)\n",
    "    expected = y_test_IN\n",
    "    predicted = model.predict(X_test_IN)\n",
    "    \n",
    "    # get accuracy score\n",
    "    my_accuracy_score = accuracy_score( expected, predicted )\n",
    "    \n",
    "    # * 100 to turn into percentage value\n",
    "    my_accuracy_score = my_accuracy_score * 100\n",
    "    \n",
    "    return my_accuracy_score\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remember,  first extract the values of y_train, before calling the classifier function\n",
    "y_train_values = y_train[\"ORG_DEPT\"].values\n",
    "\n",
    "# TEST to see if your accuracy is greater than 70%. This might take several minutes to run!!!\n",
    "test_accuracy_score = classifier( X_train, y_train_values, X_test, y_test )\n",
    "print( \"Accuracy Percentage: \" + str( test_accuracy_score ) )\n",
    "\n",
    "# TEST - is it greater than 70%?\n",
    "assert test_accuracy_score >= 70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Pipeline\n",
    "When working on machine learning projects, it is a good idea to structure your code as a modular pipeline. This has \n",
    "many advantages:\n",
    "- **Reproducibility**.\n",
    "- **Comparison**.\n",
    "- **Ability to make changes.**\n",
    "- **Ability to collaborate.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "- Hastie et al.'s [The Elements of Statistical Learning](http://statweb.stanford.edu/~tibs/ElemStatLearn/) is a classic and is available online for free.\n",
    "- James et al.'s [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/) includes less mathematics and is more approachable. It is also available online.\n",
    "- Wu et al.'s [Top 10 Algorithms in Data Mining](http://www.cs.uvm.edu/~icdm/algorithms/10Algorithms-08.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
